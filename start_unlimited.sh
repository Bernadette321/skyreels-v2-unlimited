#!/bin/bash

echo "ğŸ”¥ å¯åŠ¨ SkyReels V2 æ— é™åˆ¶æ¨¡å¼..."

# æ£€æµ‹ç¡¬ä»¶é…ç½®
GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
TOTAL_VRAM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | paste -sd+ | bc)
TOTAL_RAM=$(free -g | awk 'NR==2{print $2}')

echo "ğŸ® ç¡¬ä»¶é…ç½®:"
echo "   GPUæ•°é‡: $GPU_COUNT"
echo "   æ€»VRAM: ${TOTAL_VRAM}MB"
echo "   æ€»RAM: ${TOTAL_RAM}GB"

# æ£€æµ‹GPUå‹å·
GPU_NAMES=$(nvidia-smi --query-gpu=name --format=csv,noheader)
echo "   GPUå‹å·: $GPU_NAMES"

# è®¾ç½®æœ€ä¼˜é…ç½®
if [ $TOTAL_VRAM -gt 70000 ]; then
    echo "ğŸš€ æ£€æµ‹åˆ°é«˜ç«¯é…ç½®ï¼Œå¯ç”¨æ— é™åˆ¶æ¨¡å¼"
    export SKYREELS_MODE="unlimited"
    export SKYREELS_MAX_RESOLUTION="1080p"
    export SKYREELS_MAX_DURATION="7200"  # 120åˆ†é’Ÿ
    export SKYREELS_ENABLE_4K="true"
    export SKYREELS_BATCH_SIZE="2"
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:4096
    export OMP_NUM_THREADS=16
    
elif [ $TOTAL_VRAM -gt 40000 ]; then
    echo "ğŸ’ª æ£€æµ‹åˆ°ä¸­é«˜ç«¯é…ç½®ï¼Œå¯ç”¨æ‰©å±•æ¨¡å¼"
    export SKYREELS_MODE="extended"
    export SKYREELS_MAX_RESOLUTION="1080p"
    export SKYREELS_MAX_DURATION="3600"  # 60åˆ†é’Ÿ
    export SKYREELS_BATCH_SIZE="1"
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2048
    export OMP_NUM_THREADS=12
    
elif [ $TOTAL_VRAM -gt 20000 ]; then
    echo "âš¡ æ£€æµ‹åˆ°æ ‡å‡†é…ç½®ï¼Œå¯ç”¨æ ‡å‡†æ¨¡å¼"
    export SKYREELS_MODE="standard"
    export SKYREELS_MAX_RESOLUTION="720p"
    export SKYREELS_MAX_DURATION="1800"  # 30åˆ†é’Ÿ
    export SKYREELS_BATCH_SIZE="1"
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
    export OMP_NUM_THREADS=8
    
else
    echo "âŒ é…ç½®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦20GB VRAM"
    exit 1
fi

# å¤šGPUé…ç½®
if [ $GPU_COUNT -gt 1 ]; then
    echo "ğŸ”¥ å¯ç”¨å¤šGPUå¹¶è¡Œå¤„ç†"
    export CUDA_VISIBLE_DEVICES="0,1,2,3"  # æ ¹æ®å®é™…GPUæ•°é‡è°ƒæ•´
    export SKYREELS_MULTI_GPU="true"
    export SKYREELS_DISTRIBUTED="true"
    export PYTORCH_CUDA_ALLOC_CONF="${PYTORCH_CUDA_ALLOC_CONF},expandable_segments:True"
else
    export CUDA_VISIBLE_DEVICES="0"
    export SKYREELS_MULTI_GPU="false"
fi

# é«˜æ€§èƒ½è®¾ç½®
export MKL_NUM_THREADS=$OMP_NUM_THREADS
export NUMBA_NUM_THREADS=$OMP_NUM_THREADS
export TORCH_NUM_THREADS=$OMP_NUM_THREADS

# å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
export TORCH_BACKENDS_CUDNN_BENCHMARK="true"
export TORCH_BACKENDS_CUDA_MATMUL_ALLOW_TF32="true"
export TORCH_BACKENDS_CUDNN_ALLOW_TF32="true"

# å†…å­˜ç®¡ç†
export PYTHONUNBUFFERED="1"
export TOKENIZERS_PARALLELISM="false"

# ç¼“å­˜è®¾ç½®
export HF_HOME="/app/cache"
export TRANSFORMERS_CACHE="/app/cache"
export TORCH_HOME="/app/cache"
export HUGGINGFACE_HUB_CACHE="/app/cache"

# SkyReels V2 ç‰¹å®šè®¾ç½®
export SKYREELS_HIGH_QUALITY="true"
export SKYREELS_UNLIMITED_MODE="true"
export SKYREELS_ENABLE_AUDIO="true"
export SKYREELS_ENABLE_UPSCALING="true"

# åˆ›å»ºç›®å½•
mkdir -p /app/outputs/videos
mkdir -p /app/outputs/temp
mkdir -p /app/outputs/audio
mkdir -p /app/cache/models
mkdir -p /app/cache/diffusers
mkdir -p /app/cache/transformers
mkdir -p /app/logs

# è®¾ç½®æƒé™
chmod -R 755 /app/outputs
chmod -R 755 /app/cache
chmod -R 755 /app/logs

echo "ğŸ“ ç›®å½•ç»“æ„:"
echo "   è¾“å‡ºç›®å½•: /app/outputs"
echo "   ç¼“å­˜ç›®å½•: /app/cache"
echo "   æ—¥å¿—ç›®å½•: /app/logs"

# æ£€æŸ¥å¿…è¦æ–‡ä»¶
if [ ! -d "/app/SkyReels-V2" ]; then
    echo "âŒ SkyReels-V2 ä»£ç ç›®å½•ä¸å­˜åœ¨"
    exit 1
fi

# è®¾ç½®Pythonè·¯å¾„
export PYTHONPATH="/app/SkyReels-V2:$PYTHONPATH"

# é¢„çƒ­GPU
echo "ğŸ”¥ é¢„çƒ­GPU..."
python3 -c "
import torch
import gc
import time

if torch.cuda.is_available():
    print(f'æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªGPU')
    for i in range(torch.cuda.device_count()):
        torch.cuda.set_device(i)
        torch.cuda.empty_cache()
        
        # é¢„çƒ­æ“ä½œ
        print(f'é¢„çƒ­GPU {i}...')
        x = torch.randn(2048, 2048, device=f'cuda:{i}')
        y = torch.mm(x, x)
        del x, y
        torch.cuda.empty_cache()
        gc.collect()
        
    print('âœ… GPUé¢„çƒ­å®Œæˆ')
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f'GPU {i}: {props.name} ({props.total_memory/1024**3:.1f}GB)')
else:
    print('âŒ æ²¡æœ‰æ£€æµ‹åˆ°å¯ç”¨çš„GPU')
    exit(1)
"

# æ£€æŸ¥Pythonç¯å¢ƒ
echo "ğŸ æ£€æŸ¥Pythonç¯å¢ƒ..."
echo "   Pythonç‰ˆæœ¬: $(python3 --version)"
echo "   PyTorchç‰ˆæœ¬: $(python3 -c 'import torch; print(torch.__version__)')"
echo "   CUDAç‰ˆæœ¬: $(python3 -c 'import torch; print(torch.version.cuda if torch.cuda.is_available() else \"Not available\")')"

# å¯åŠ¨GPUç›‘æ§ï¼ˆåå°ï¼‰
echo "ğŸ“Š å¯åŠ¨GPUç›‘æ§..."
{
    while true; do
        timestamp=$(date '+%Y-%m-%d %H:%M:%S')
        
        # è·å–GPUç»Ÿè®¡ä¿¡æ¯
        gpu_stats=$(nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total,temperature.gpu,power.draw --format=csv,noheader,nounits 2>/dev/null)
        
        if [ ! -z "$gpu_stats" ]; then
            echo "[$timestamp] GPU Stats:" >> /app/logs/gpu_monitor.log
            echo "$gpu_stats" >> /app/logs/gpu_monitor.log
            
            # æ£€æŸ¥æ¯ä¸ªGPUçš„VRAMä½¿ç”¨ç‡
            while IFS=',' read -r gpu_id gpu_name gpu_util vram_used vram_total temp power; do
                vram_usage=$((vram_used * 100 / vram_total))
                if [ $vram_usage -gt 90 ]; then
                    echo "[$timestamp] âš ï¸  GPU $gpu_id HIGH VRAM: ${vram_usage}%" >> /app/logs/gpu_monitor.log
                fi
                if [ ${temp%.*} -gt 80 ]; then
                    echo "[$timestamp] ğŸŒ¡ï¸  GPU $gpu_id HIGH TEMP: ${temp}Â°C" >> /app/logs/gpu_monitor.log
                fi
            done <<< "$gpu_stats"
        fi
        
        sleep 30
    done
} &

# å¯åŠ¨ç³»ç»Ÿç›‘æ§ï¼ˆåå°ï¼‰
echo "ğŸ“ˆ å¯åŠ¨ç³»ç»Ÿç›‘æ§..."
{
    while true; do
        timestamp=$(date '+%Y-%m-%d %H:%M:%S')
        
        # ç³»ç»Ÿå†…å­˜
        mem_info=$(free -m | awk 'NR==2{printf "Used: %sMB (%.1f%%), Available: %sMB", $3, $3*100/$2, $7}')
        echo "[$timestamp] Memory: $mem_info" >> /app/logs/system_monitor.log
        
        # ç£ç›˜ç©ºé—´
        disk_info=$(df -h /app | awk 'NR==2{printf "Used: %s (%s), Available: %s", $3, $5, $4}')
        echo "[$timestamp] Disk: $disk_info" >> /app/logs/system_monitor.log
        
        sleep 60
    done
} &

# å¯åŠ¨APIæœåŠ¡å™¨
echo "ğŸŒ å¯åŠ¨æ— é™åˆ¶SkyReels V2 APIæœåŠ¡å™¨..."
echo "ğŸ”— æœåŠ¡åœ°å€: http://0.0.0.0:8000"
echo "ğŸ“‹ APIæ–‡æ¡£: http://0.0.0.0:8000/docs"
echo "ğŸ“Š å¥åº·æ£€æŸ¥: http://0.0.0.0:8000/health"

cd /app

# å¯åŠ¨ä¸»æœåŠ¡
exec gunicorn \
    --bind 0.0.0.0:8000 \
    --workers 1 \
    --worker-class uvicorn.workers.UvicornWorker \
    --timeout 0 \
    --keep-alive 300 \
    --max-requests 0 \
    --worker-connections 1000 \
    --preload \
    --log-level info \
    --access-logfile /app/logs/access.log \
    --error-logfile /app/logs/error.log \
    --capture-output \
    api_server_unlimited:app 