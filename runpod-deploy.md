# RunPod SkyReels V2 æ— é™åˆ¶éƒ¨ç½²æŒ‡å—

## ğŸ¯ ç›®æ ‡
åœ¨RunPodä¸Šéƒ¨ç½²SkyReels V2æ— é™åˆ¶ç‰ˆæœ¬ï¼Œæ”¯æŒä»»æ„æ—¶é•¿å’Œåˆ†è¾¨ç‡çš„è§†é¢‘ç”Ÿæˆã€‚

---

## ğŸ”¥ æ¨èRunPodé…ç½®

### é«˜æ€§èƒ½é…ç½® (æ¨è)
```yaml
é…ç½®è§„æ ¼:
ğŸš€ GPU: NVIDIA A100 80GB æˆ– H100 80GB
ğŸš€ vCPU: 32+ cores
ğŸš€ RAM: 128GB+
ğŸš€ å­˜å‚¨: 500GB+ NVMe SSD
ğŸš€ ç½‘ç»œ: é«˜é€Ÿè¿æ¥

é¢„æœŸæ€§èƒ½:
âœ… 1080P 60åˆ†é’Ÿ: ~60-90åˆ†é’Ÿç”Ÿæˆ
âœ… 720P 60åˆ†é’Ÿ: ~35-50åˆ†é’Ÿç”Ÿæˆ
âœ… æ”¯æŒ4KçŸ­è§†é¢‘
âœ… æ— æ—¶é•¿é™åˆ¶

æˆæœ¬: ~$3-5/å°æ—¶
```

### æ€§ä»·æ¯”é…ç½®
```yaml
é…ç½®è§„æ ¼:
ğŸ’ª GPU: NVIDIA A100 40GB
ğŸ’ª vCPU: 24+ cores
ğŸ’ª RAM: 64GB+
ğŸ’ª å­˜å‚¨: 300GB+ SSD

æ€§èƒ½è¡¨ç°:
âœ… 1080P 30åˆ†é’Ÿ: ~45-60åˆ†é’Ÿç”Ÿæˆ
âœ… 720P 60åˆ†é’Ÿ: ~50-70åˆ†é’Ÿç”Ÿæˆ
âœ… ç¨³å®šå¯é 

æˆæœ¬: ~$2-3/å°æ—¶
```

---

## ğŸ“‹ éƒ¨ç½²æ­¥éª¤

### 1. åˆ›å»ºRunPodå®ä¾‹

```bash
# ç™»å½•RunPodæ§åˆ¶å°
# é€‰æ‹© "Deploy" -> "Pods"

# æ¨èé…ç½®ç­›é€‰:
GPU: A100 80GB SXM æˆ– H100 80GB
vCPU: 32+ cores
RAM: 128GB+
Storage: 500GB+ NVMe
```

### 2. Dockeré•œåƒé…ç½®

#### æ–¹å¼1: ä½¿ç”¨é¢„æ„å»ºé•œåƒ (æ¨è)
```yaml
Dockeré…ç½®:
é•œåƒ: skyreels/skyreels-v2:unlimited
ç«¯å£æ˜ å°„: 8000:8000
å¯åŠ¨å‘½ä»¤: /app/start_unlimited.sh
```

#### æ–¹å¼2: ç°åœºæ„å»º
```yaml
Dockeré…ç½®:
é•œåƒ: nvidia/cuda:12.1-devel-ubuntu22.04
ç«¯å£æ˜ å°„: 8000:8000
å¯åŠ¨å‘½ä»¤: /bin/bash
```

### 3. ç¯å¢ƒå˜é‡è®¾ç½®

```bash
# åŸºç¡€é…ç½®
SKYREELS_UNLIMITED_MODE=true
SKYREELS_MAX_RESOLUTION=1080p
SKYREELS_MAX_DURATION=7200  # 2å°æ—¶ï¼Œå¯è°ƒæ•´æ›´å¤§
SKYREELS_ENABLE_4K=true
SKYREELS_HIGH_QUALITY=true

# GPUä¼˜åŒ–
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:4096
OMP_NUM_THREADS=16
MKL_NUM_THREADS=16

# ç¼“å­˜ç›®å½•
HF_HOME=/workspace/cache
TRANSFORMERS_CACHE=/workspace/cache
TORCH_HOME=/workspace/cache
```

### 4. å·æŒ‚è½½è®¾ç½®

```yaml
æŒ‚è½½é…ç½®:
- /workspace/outputs:/app/outputs  # è¾“å‡ºæ–‡ä»¶
- /workspace/cache:/app/cache      # æ¨¡å‹ç¼“å­˜
- /workspace/logs:/app/logs        # æ—¥å¿—æ–‡ä»¶
```

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²è„šæœ¬

### ä¸€é”®éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash

echo "ğŸ”¥ å¼€å§‹éƒ¨ç½²SkyReels V2æ— é™åˆ¶ç‰ˆ..."

# æ›´æ–°ç³»ç»Ÿ
apt-get update && apt-get upgrade -y

# å®‰è£…åŸºç¡€ä¾èµ–
apt-get install -y git wget curl python3.10 python3-pip

# å…‹éš†é¡¹ç›®
git clone https://github.com/your-repo/skyreels-v2-unlimited.git /app
cd /app

# æ„å»ºDockeré•œåƒ
docker build -f Dockerfile.unlimited -t skyreels-v2:unlimited .

# å¯åŠ¨å®¹å™¨
docker run -d \
  --name skyreels-unlimited \
  --gpus all \
  -p 8000:8000 \
  -v /workspace/outputs:/app/outputs \
  -v /workspace/cache:/app/cache \
  -v /workspace/logs:/app/logs \
  -e SKYREELS_UNLIMITED_MODE=true \
  -e SKYREELS_MAX_DURATION=7200 \
  -e SKYREELS_ENABLE_4K=true \
  skyreels-v2:unlimited

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "ğŸŒ APIåœ°å€: http://localhost:8000"
echo "ğŸ“‹ APIæ–‡æ¡£: http://localhost:8000/docs"
```

---

## ğŸ”§ æ‰‹åŠ¨éƒ¨ç½²æ­¥éª¤

### 1. ç³»ç»Ÿå‡†å¤‡
```bash
# è¿æ¥åˆ°RunPodå®ä¾‹
ssh root@your-pod-ip

# æ›´æ–°ç³»ç»Ÿ
apt-get update && apt-get upgrade -y

# å®‰è£…NVIDIAé©±åŠ¨å’ŒDocker (å¦‚æœæœªå®‰è£…)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list

apt-get update && apt-get install -y nvidia-docker2
systemctl restart docker
```

### 2. ä¸‹è½½é¡¹ç›®ä»£ç 
```bash
# åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p /workspace/{outputs,cache,logs}
cd /workspace

# å…‹éš†é¡¹ç›®
git clone <your-skyreels-repo> skyreels-v2
cd skyreels-v2
```

### 3. æ„å»ºDockeré•œåƒ
```bash
# æ„å»ºæ— é™åˆ¶ç‰ˆé•œåƒ
docker build -f Dockerfile.unlimited -t skyreels-v2:unlimited .

# æŸ¥çœ‹é•œåƒ
docker images
```

### 4. å¯åŠ¨æœåŠ¡
```bash
# å¯åŠ¨æ— é™åˆ¶å®¹å™¨
docker run -d \
  --name skyreels-unlimited \
  --gpus all \
  --restart unless-stopped \
  -p 8000:8000 \
  -v /workspace/outputs:/app/outputs \
  -v /workspace/cache:/app/cache \
  -v /workspace/logs:/app/logs \
  -e SKYREELS_UNLIMITED_MODE=true \
  -e SKYREELS_MAX_RESOLUTION=1080p \
  -e SKYREELS_MAX_DURATION=7200 \
  -e SKYREELS_ENABLE_4K=true \
  -e SKYREELS_HIGH_QUALITY=true \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:4096 \
  skyreels-v2:unlimited

# æŸ¥çœ‹å¯åŠ¨çŠ¶æ€
docker ps
docker logs skyreels-unlimited
```

---

## ğŸ“Š æœåŠ¡éªŒè¯

### 1. å¥åº·æ£€æŸ¥
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æŸ¥çœ‹GPUä¿¡æ¯
curl http://localhost:8000/models/info

# æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
curl http://localhost:8000/system/stats
```

### 2. æµ‹è¯•è§†é¢‘ç”Ÿæˆ
```bash
# æµ‹è¯•çŸ­è§†é¢‘ç”Ÿæˆ
curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "A beautiful sunset over the ocean with waves",
    "resolution": "720p",
    "duration": 30,
    "quality": "high"
  }'
```

### 3. æŸ¥çœ‹æ—¥å¿—
```bash
# æŸ¥çœ‹APIæ—¥å¿—
docker logs -f skyreels-unlimited

# æŸ¥çœ‹GPUç›‘æ§
tail -f /workspace/logs/gpu_monitor.log

# æŸ¥çœ‹ç³»ç»Ÿç›‘æ§
tail -f /workspace/logs/system_monitor.log
```

---

## ğŸ”§ RunPodç‰¹å®šä¼˜åŒ–

### 1. ç½‘ç»œé…ç½®
```bash
# è®¾ç½®RunPodä»£ç† (è‡ªåŠ¨é…ç½®)
export RUNPOD_POD_ID=$(curl -s http://metadata.runpod.io/v1/pod/id)
export PUBLIC_URL="https://${RUNPOD_POD_ID}-8000.proxy.runpod.net"

echo "ğŸŒ Public URL: $PUBLIC_URL"
```

### 2. æŒä¹…åŒ–å­˜å‚¨
```bash
# åˆ›å»ºæŒä¹…åŒ–ç›®å½•
mkdir -p /workspace/persistent/{models,outputs,cache}

# è½¯é“¾æ¥åˆ°åº”ç”¨ç›®å½•
ln -sf /workspace/persistent/models /app/cache/models
ln -sf /workspace/persistent/outputs /app/outputs
ln -sf /workspace/persistent/cache /app/cache
```

### 3. è‡ªåŠ¨é‡å¯é…ç½®
```bash
# åˆ›å»ºsystemdæœåŠ¡
cat > /etc/systemd/system/skyreels.service << 'EOF'
[Unit]
Description=SkyReels V2 Unlimited
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/bin/docker start skyreels-unlimited
ExecStop=/usr/bin/docker stop skyreels-unlimited

[Install]
WantedBy=multi-user.target
EOF

# å¯ç”¨æœåŠ¡
systemctl enable skyreels.service
systemctl start skyreels.service
```

---

## ğŸ¯ n8nå·¥ä½œæµé›†æˆ

### 1. æ›´æ–°n8nå·¥ä½œæµé…ç½®
```json
{
  "skyreelsEndpoint": "https://your-pod-id-8000.proxy.runpod.net"
}
```

### 2. æµ‹è¯•è¿æ¥
```bash
# åœ¨n8nä¸­æµ‹è¯•å¥åº·æ£€æŸ¥èŠ‚ç‚¹
GET https://your-pod-id-8000.proxy.runpod.net/health
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### 1. GPUç›‘æ§
```bash
# å®æ—¶GPUçŠ¶æ€
watch -n 1 nvidia-smi

# GPUå†å²æ•°æ®
tail -f /workspace/logs/gpu_monitor.log
```

### 2. APIç›‘æ§
```bash
# APIè®¿é—®æ—¥å¿—
tail -f /workspace/logs/access.log

# APIé”™è¯¯æ—¥å¿—  
tail -f /workspace/logs/error.log
```

### 3. ç³»ç»Ÿç›‘æ§
```bash
# ç³»ç»Ÿèµ„æº
htop

# ç£ç›˜ä½¿ç”¨
df -h

# å†…å­˜ä½¿ç”¨
free -h
```

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³

1. **GPUå†…å­˜ä¸è¶³**
```bash
# æ¸…ç†GPUç¼“å­˜
curl -X POST http://localhost:8000/system/cleanup

# é‡å¯å®¹å™¨
docker restart skyreels-unlimited
```

2. **æœåŠ¡æ— æ³•å¯åŠ¨**
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker logs --details skyreels-unlimited

# æ£€æŸ¥GPUå¯ç”¨æ€§
nvidia-smi
```

3. **ç”Ÿæˆé€Ÿåº¦æ…¢**
```bash
# æ£€æŸ¥GPUä½¿ç”¨ç‡
nvidia-smi

# ä¼˜åŒ–ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:8192
export OMP_NUM_THREADS=32
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å®šæœŸæ¸…ç†**: æ¯å¤©æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ—§ä»»åŠ¡
2. **ç›‘æ§èµ„æº**: ç›‘æ§GPUå†…å­˜å’Œç£ç›˜ä½¿ç”¨æƒ…å†µ
3. **å¤‡ä»½æ¨¡å‹**: å®šæœŸå¤‡ä»½ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶
4. **æ—¥å¿—è½®è½¬**: é…ç½®æ—¥å¿—è½®è½¬é¿å…ç£ç›˜æ»¡
5. **å®‰å…¨è®¿é—®**: ä½¿ç”¨RunPodå†…ç½®çš„å®‰å…¨è®¿é—®æœºåˆ¶

---

éƒ¨ç½²å®Œæˆåï¼Œæ‚¨å°±æ‹¥æœ‰äº†ä¸€ä¸ªæ”¯æŒæ— é™åˆ¶é•¿è§†é¢‘ç”Ÿæˆçš„å¼ºå¤§AIæœåŠ¡ï¼ğŸš€ 